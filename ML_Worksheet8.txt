                                                                MACHINE LEARNING
                                                                 ASSIGNMENT - 8

1. What is the advantage of hierarchical clustering over K-means clustering?
A) Hierarchical clustering is computationally less expensive
B) In hierarchical clustering you don’t need to assign number of clusters in beginning
C) Both are equally proficient 
D) None of these
Answer: B) In hierarchical clustering you don’t need to assign number of clusters in beginning

2. Which of the following hyper parameter(s), when increased may cause random forest to over fit the data?
A) max_depth                  B) n_estimators 
C) min_samples_leaf           D) min_samples_splits
Answer: A) max_depth  

3. Which of the following is the least preferable resampling method in handling imbalance datasets?
A) SMOTE                      B) RandomOverSampler
C) RandomUnderSampler         D) ADASYN
Answer: C) RandomUnderSampler

4. Which of the following statements is/are true about “Type-1” and “Type-2” errors?
1. Type1 is known as false positive and Type2 is known as false negative.
2. Type1 is known as false negative and Type2 is known as false positive.
3. Type1 error occurs when we reject a null hypothesis when it is actually true.
A) 1 and 2               B) 1 only
C) 1 and 3               D) 2 and 3
Answer: C) 1 and 3 

5. Arrange the steps of k-means algorithm in the order in which they occur:
1. Randomly selecting the cluster centroids
2. Updating the cluster centroids iteratively
3. Assigning the cluster points to their nearest center
A) 3-1-2                  B) 2-1-3
C) 3-2-1                  D) 1-3-2
Answer: D) 1-3-2

6. Which of the following algorithms is not advisable to use when you have limited CPU resources and time, and when the data set is relatively large?
A) Decision Trees         B) Support Vector Machines
C) K-Nearest Neighbors    D) Logistic Regression
Answer: B) Support Vector Machines

7. What is the main difference between CART (Classification and Regression Trees) and CHAID (Chi Square Automatic Interaction Detection) Trees?
A) CART is used for classification, and CHAID is used for regression.
B) CART can create multiway trees (more than two children for a node), and CHAID can only create binary trees (a maximum of two children for a node).
C) CART can only create binary trees (a maximum of two children for a node), and CHAID can create multiway trees (more than two children for a node)
D) None of the above
Answer: C) CART can only create binary trees (a maximum of two children for a node), and CHAID can create multiway trees (more than two children for a node)

8. In Ridge and Lasso regularization if you take a large value of regularization constant(lambda), which of the following things may occur?
A) Ridge will lead to some of the coefficients to be very close to 0
B) Lasso will lead to some of the coefficients to be very close to 0
C) Ridge will cause some of the coefficients to become 0
D) Lasso will cause some of the coefficients to become 0.
Answer: A) Ridge will lead to some of the coefficients to be very close to 0
D) Lasso will cause some of the coefficients to become 0.

9. Which of the following methods can be used to treat two multi-collinear features?
A) remove both features from the dataset
B) remove only one of the features 
C) Use ridge regularization 
D) use Lasso regularization 
Answer: B) remove only one of the features 
C) Use ridge regularization 
D) use Lasso regularization 

10. After using linear regression, we find that the bias is very low, while the variance is very high. What are the possible reasons for this?
A) Overfitting          B) Multicollinearity
C) Underfitting         D) Outliers
Answer: A) Overfitting   
B) Multicollinearity

11. In which situation One-hot encoding must be avoided? Which encoding technique can be used in such a case?
Answer: If the categorical data is ordinal, we can't use one hot encoding. One hot encoding is applied when the number of categorical features is less and categorical feature is not ordinal. In that case,we use label encoding.

12. In case of data imbalance problem in classification, what techniques can be used to balance the dataset? Explain them briefly.
Answer: Techniques used to balance the dataset:
Oversampling Methods:
RandomOverSampler method: It is a method of oversampling to randomly sample the minority classes and simply duplicate the sampled observations.
SMOTE method: Synthetic Minority Over-sampling Technique(SMOTE) is a technique that generates new observations by interposing between observations in the existing data.

Undersampling Methods:
RandomunderSampler method: It samples the majority class at random until it reaches a similar number of observations as the minority classes.
NearMiss  method: It samples the majority class at random until it reaches a similar number of observations as the minority classes.

13. What is the difference between SMOTE and ADASYN sampling techniques?
Answer: ADASYN is an algorithm which generates synthetic data and not copies the same minority data whereas SMOTE generates synthetic samples from the minority class. The key difference between ADASYN and SMOTE is that the former uses a density distribution, as a criterion to automatically decide the number of synthetic samples that must be generated for each minority sample by adaptively changing the weights of the different minority samples to compensate for the skewed distributions.

14. What is the purpose of using GridSearchCV? Is it preferable to use in case of large datasets? Why or why not?
Answer: Purpose of using GridSearchCV:
The performance of a model significantly depends on the value of hyperparameters. we need to try all possible values to know the optimal values.GridSearchCV helps to loop through predefined hyperparameters and fit your estimator (model) on your training set. 
GridSearchCV can be used in hyperparameter tuning for large datasets. But it is disadvantageous over large datasets as it does a large number of fits which takes a lot of time and is computationally very heavy. But it is very helpful tool if the dataset is not very large.

15. List down some of the evaluation metric used to evaluate a regression model. Explain each of them in brief.
Answer: 
==> MEAN SQUARED ERROR:
It calculates the average of the square of the errors between the actual and the predicted values.
Lower the MEAN SQUARED ERROR value, better the regression model.
MEAN SQUARED ERROR = (1/n) * Σ(actual – predicted)2
Here, n is the number of data points.
The problem with MSE is that since the values are squared the unit of measurement is changed.
It is sensitive to outliers.

==> ROOT MEAN SQUARED ERROR:
RMSE is the most popular metric to measure the error of a regression model.
It is calculated as the square root of the average squared distance between the actual and the predicted values.
In simple terms, the square root of the mean squared error will give RMSE.
Since we are, taking the square root it reverts the unit of measurement to its original scale.
It is sensitive to outliers.

==> MEAN ABSOLUTE PERCENTAGE ERROR(MAPE):
MAPE measures the error in percentage terms.
MAPE is calculated as the absolute difference between the actual and predicted values divide over every observation.
It is multiplied by 100 to make it a percentage error.
MAPE = (1/n) * Σ(|actual – predicted| / |actual|) * 100
Where n is the size of the sample
MAPE can be used to compare two models of different scales.
It is robust to outliers.

==> MEAN ABSOLUTE ERROR(MAE):
It calculates the difference between the actual and the predicted values.
MEAN ABSOLUTE ERROR(MAE): (1/n) * Σ|actual – predicted|
It is robust to outliers.

==> R2(R-squared): R-squared indicates how much variation of a dependent variable is explained by the independent variable(s) in a regression model.It is also known as the coefficient of determination. 
It is calculated by 
R2 = 1-(SSres/SStot)

SSres: sum of squared residuals
SStot: Total Sum of Squares.

==> Adjusted R2: Adjusted R-squared is a modified version of R-squared that has been adjusted for the number of predictors in the model.
The main difference between R2 and Adjusted R2 is R2 assumes that every single variable explains the variation in the dependent variable. The adjusted R2 tells you the percentage of variation explained by only the independent variables that actually affect the dependent variable.

The adjusted R-squared increases only if the new term improves the model more than would be expected by chance. It decreases when a predictor improves the model by less than expected by chance.

R2adjusted = 1-[(1-R2)(N-1)/N-P-1]
Where N = Total sample size
P = Number of predictors
R2 = Sample R-square