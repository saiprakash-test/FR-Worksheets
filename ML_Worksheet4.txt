                                                                WORKSHEET-4
                                                              MACHINE LEARNING
                                    
1. The value of correlation coefficient will always be:
A) between 0 and 1                   B) greater than -1
C) between -1 and 1                  D) between 0 and -1
Answer: C) between -1 and 1

2. Which of the following cannot be used for dimensionality reduction?
A) Lasso Regularisation              B) PCA
C) Recursive feature elimination     D) Ridge Regularisation
Answer: D) Ridge Regularisation

3. Which of the following is not a kernel in Support Vector Machines?
A) linear                            B) Radial Basis Function
C) hyperplane                        D) polynomial
Answer: C) hyperplane 

4. Amongst the following, which one is least suitable for a dataset having non-linear decision boundaries?
A) Logistic Regression                B) Naïve Bayes Classifier
C) Decision Tree Classifier           D) Support Vector Classifier
Answer: B) Naïve Bayes Classifier

5. In a Linear Regression problem, ‘X’ is independent variable and ‘Y’ is dependent variable, where ‘X’ represents weight in pounds. If you convert the unit of ‘X’ to kilograms, then new coefficient of ‘X’ will be? (1 kilogram = 2.205 pounds)
A) 2.205 × old coefficient of ‘X’     B) same as old coefficient of ‘X’
C) old coefficient of ‘X’ ÷ 2.205     D) Cannot be determined
Answer: C) old coefficient of ‘X’ ÷ 2.205

6. As we increase the number of estimators in ADABOOST Classifier, what happens to the accuracy of the model?
A) remains same                       B) increases
C) decreases                          D) none of the above
Answer: B) increases

7. Which of the following is not an advantage of using random forest instead of decision trees?
A) Random Forests reduce overfitting
B) Random Forests explains more variance in data then decision trees
C) Random Forests are easy to interpret
D) Random Forests provide a reliable feature importance estimate
Answer: C) Random Forests are easy to interpret

8. Which of the following are correct about Principal Components?
A) Principal Components are calculated using supervised learning techniques
B) Principal Components are calculated using unsupervised learning techniques
C) Principal Components are linear combinations of Linear Variables.
D) All of the above
Answer: B) Principal Components are calculated using unsupervised learning techniques
        C) Principal Components are linear combinations of Linear Variables.

9. Which of the following are applications of clustering?
A) Identifying developed, developing and under-developed countries on the basis of factors like GDP,poverty index, employment rate, and living index
B) Identifying loan defaulters in a bank on the basis of previous years’ data of loan accounts.
C) Identifying spam or ham emails
D) Identifying different segments of disease based on BMI, blood pressure, cholesterol, blood sugar levels.
Answer: C) Identifying spam or ham emails
        D) Identifying different segments of disease based on BMI, blood pressure, cholesterol, blood sugar levels.

10. Which of the following is(are) hyper parameters of a decision tree?
A) max_depth                             B) max_features
C) n_estimators                          D) min_samples_leaf
Answer: A) max_depth                             B) max_features                          D) min_samples_leaf

11. What are outliers? Explain the Inter Quartile Range (IQR) method for outlier detection.
Answer: 
Outliers: An outlier is a data point that differs significantly from other observations. An Outlier may suggest experimental errors, variability in a measurement, or an anomaly. 
Inter Quartile Range (IQR): It is a measure variability in which data is sorted in ascending order and split into 4 equal parts. The interquartile range (IQR) is the distance between the first and third quartile. The formula is given by IQR = Q3-Q1.
Q1= represents the 25th percentile of the data
Q2= represents the 50th percentile of the data
Q3= represents the 75th percentile of the data.

12. What is the primary difference between bagging and boosting algorithms?
Answer:
Bagging and Boosting are homogeneous weak learners’ model.But, bagging learners learns from each other independently in parallel and combines them for determining the model average whereas boosting learners learn sequentially and adaptively to improve model predictions of a learning algorithm.

13. What is adjusted R2 in linear regression. How is it calculated?
Answer: Adjusted R2 has the capability to decrease with the addition of less significant variables, thus resulting in a more reliable and accurate evaluation. It is calculated by using the formula:  R2adj=1−[(1−R2)(n−1)/n−k−1].

14. What is the difference between standardisation and normalisation?
Answer: Standardisation and normalisation are different types of scaling techniques.In standardisation the values are standardised in such a way that mean of the attribute becomes zero and the resultant distribution has a unit standard deviation whereas normalisation values are shifted and rescaled so that they end up ranging between 0 and 1. 

15. What is cross-validation? Describe one advantage and one disadvantage of using cross-validation.
Answer: Cross Validation is a technique for assessing the effectiveness of your model, particularly in cases where you need to mitigate overfitting. 
Advantage:
==> Reduces overfitting
Disadvantage:
==> Needs expensive computation